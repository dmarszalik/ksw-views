{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('youtube_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(data_search[0]['items'])\n",
    "\n",
    "for i in range(len(data_search)-1):\n",
    "    df = pd.concat([df, pd.DataFrame(data_search[i+1]['items'])])\n",
    "df = pd.DataFrame(df['snippet'])\n",
    "df = df['snippet'].apply(pd.Series)\n",
    "df = pd.concat([df, df_views], axis=1)\n",
    "df = df.drop(['thumbnails', 'channelId', 'publishedAt'], axis=1)\n",
    "df_filtered = df[df['channelTitle'] != 'KSW']\n",
    "clean_df = standardize_text(df_filtered, \"title\")\n",
    "clean_df[\"tokens\"] = clean_df[\"title\"].apply(tokenizer.tokenize)\n",
    "clean_df.head(20)\n",
    "clean_df['viewCount'].describe()\n",
    "clean_df['publishTime'] = pd.to_datetime(clean_df['publishTime'])\n",
    "clean_df['hour'] = clean_df['publishTime'].dt.hour\n",
    "clean_df['dayPart'] = pd.cut(clean_df['hour'], bins=[0, 12, 18, 24], labels=['morning', 'afternoon', 'evening'], right=False)\n",
    "clean_df['dayPart'] = preprocessing.LabelEncoder().fit_transform(clean_df['dayPart'])\n",
    "clean_df['viewCount'] = clean_df['viewCount'].astype(float)\n",
    "clean_df['view_level'] = pd.cut(clean_df['viewCount'], bins=[0, 10000, 25000, 50000, 75000, 100000, 150000, 200000, 10000000], labels=['0-10tys', '10-25tys', '25-50tys', '50-75tys', '75-100tys', '100-150tys', '150-200tys', '>200tys'], right=False)\n",
    "\n",
    "sns.displot(clean_df['viewCount'])\n",
    "plt.xlim(0,200000)\n",
    "clean_df['view_level'][0:10]\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(clean_df['view_level'])\n",
    "clean_df['view_level'] = encoder.transform(clean_df['view_level'])\n",
    "\n",
    "\n",
    "clean_df['view_level'][0:10]\n",
    "clean_df.head()\n",
    "df_learn = clean_df.drop(['description', 'channelTitle', 'liveBroadcastContent', 'publishTime', 'hour'], axis=1)\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word', token_pattern=r'\\w+')\n",
    "X = vectorizer.fit_transform(df_learn['title'])\n",
    "y = df_learn['view_level']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, stratify = y)\n",
    "print(X_train[:10])\n",
    "def get_metrics(y_test, y_predicted):  \n",
    "    # true positives / (true positives+false positives)\n",
    "    precision = precision_score(y_test, y_predicted, pos_label=None,\n",
    "                                    average='weighted')             \n",
    "    # true positives / (true positives + false negatives)\n",
    "    recall = recall_score(y_test, y_predicted, pos_label=None,\n",
    "                              average='weighted')\n",
    "    \n",
    "    # harmonic mean of precision and recall\n",
    "    f1 = f1_score(y_test, y_predicted, pos_label=None, average='weighted')\n",
    "    \n",
    "    # true positives + true negatives/ total\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    return accuracy, precision, recall, f1\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.winter):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, fontsize=20)\n",
    "    plt.yticks(tick_marks, classes, fontsize=20)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", \n",
    "                 color=\"white\" if cm[i, j] < thresh else \"black\", fontsize=40)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize=30)\n",
    "    plt.xlabel('Predicted label', fontsize=30)\n",
    "\n",
    "    return plt\n",
    "ovo_clf = OneVsOneClassifier(LogisticRegression(C=30.0, solver='newton-cg', multi_class='multinomial',penalty='l2'))\n",
    "ovo_clf.fit(X_train, y_train)\n",
    "\n",
    "ovr_clf = OneVsRestClassifier(LogisticRegression(C=30.0, solver='newton-cg', multi_class='multinomial',penalty='l2'))\n",
    "ovr_clf.fit(X_train, y_train)\n",
    "\n",
    "y_predict_ovo = ovo_clf.predict(X_test)\n",
    "y_predict_ovr = ovr_clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# scoring model \n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_predict_ovr)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))\n",
    "# i'll be focusing on increasing precision cause I want to prove to cuustomer that he can feel confident about predictions (not to feel it is to optimistic)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_predict_ovr)\n",
    "\n",
    "#np.fill_diagonal(norm_cm, 0)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = cm)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "cm_display.plot(ax = ax)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "decoded_labels = encoder.inverse_transform(y_predict_ovr)\n",
    "\n",
    "print(\"Odkodowane wartoÅ›ci:\", decoded_labels)"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "report_row_ids": [
    "wmefQcSS7EhPljXTnambyv",
    "yhj46oHsWw27P8hyYIIDWY",
    "ODWm8jImNxfMeYgrLS2V7i",
    "uAtpGmFt0qCZFU40rUh7mJ",
    "txbh56OBFNALZvdfyQ1ljq",
    "BzunFLYd4jDSKPiGJuxnNF",
    "1ldMS6RsMvBolrT1ot1INf",
    "Yfmg9YjpevOlwcwDIb5X0P",
    "iawKVNZPX7klPJyiUd1uwu",
    "DQpziOkVbHBlEEBm5i1AHT",
    "RlBCvcTDNcQGhEHjUGKOeb",
    "h3k641hFrjSG6fcyHHA0pO",
    "JGXySPamRKKXOBs9WrOOxq",
    "1gP3V90njSnK84RtBb8Sfp",
    "Lr7Fbx1FoFZaKCU1ld0PdQ",
    "7ZUrUxQY9bNgYlDL5obVrM",
    "3NUcLkV5mGsy1PtVwNhECz",
    "xHOoC4zWMMwhTP7DHwLIKH",
    "tM0T5r2CoUvbZjKjLoG8uK",
    "jFsRMg7jAyVuEDJtD1xseF"
   ],
   "version": 3
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
